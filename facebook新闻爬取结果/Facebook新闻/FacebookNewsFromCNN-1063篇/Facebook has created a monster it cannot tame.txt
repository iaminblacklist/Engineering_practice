Last week, two men and two women were arrested and now face hate crime and kidnapping charges for the abduction and torture of a man in Chicago. The city is notorious for its violent crime. The difference this time was that the crime was broadcast live to thousands of viewers around the world through Facebook. For at least half an hour, Brittany Covington filmed as her sister and friends bound and tortured the man, streaming the assault through Facebook's much-advertised Live app. Unsurprisingly, the video went viral. Many questioned why it reportedly took so long for Facebook to remove the video, others questioned the police response, while others were simply shocked and upset. As a video that is horrifying and brutal, however, it's merely the latest outrage in a well-established digital tradition.  Violence and death have been a staple of the Internet for decades. Websites such as Rotten, Ogrish and Bestgore emerged in the 90s and 00s, archiving footage of traffic accidents, autopsies and execution videos. The mantle has most recently been passed to LiveLeak, a British website started by the same team as Ogrish, which hosts graphic videos of rapes, murders and deaths. As of July 2016, Alexa ranks it as one of the top thousand websites in the world, with millions of visitors a day and multimillion dollar revenues. Despite LiveLeak's popularity, it is fair to say that this kind of content has usually lurked in the shadowy corners of the web. There's an argument to say that this is still largely the case. The great Internet companies -- Google and Facebook -- have pursued a relentless campaign of sanitizing the experience of surfing the web. For many of their hundreds of millions of users, these companies' sites make up a near totality of their web experience, and holding the mainstream means keeping it clean. This is no mean feat, especially when the vast majority of the effort going into moderating the billions of messages that flow through their platforms is manual. Relying on users to report a piece of content is the norm, supplemented by an army of outsourced administrators. The bleak reality of this -- surely one of the worst jobs on the Internet -- is brought to life in this Wired article. As the number of Internet users has swelled from million to billions, the number of websites they are likely to spend their time on has probably decreased.  The 90s and 00s saw an explosion in the number and variety of sites, but the last 10 years has seen a consolidation by Facebook, Google and Microsoft of the time we spend online. Add to this a change in user expectation and you have a recipe for disaster: where once it was perfectly acceptable to post a reply on a forum and wait for an administrator to approve it, this would be utterly unthinkable to most people in 2017. The impact on Facebook's share price, not to mention the free and open debate the site enshrines, of pre-moderation -- "hold on, we're just checking the photo you've tried to post is OK" -- would be absolutely catastrophic. Facebook Live is the latest example of this drive toward breaking down the barriers and filters between you and an audience. Live video, streaming with a click, is beamed to an audience of millions without any hope of the content being checked before it hits the eyeballs responsible for Facebook's billions of pounds of revenue. The challenges of fighting against filters are well known. In the wake of the murder of a television anchor in America live on air, both Facebook and Twitter came under fire for automatically playing the video. The same was said after the recent murder of the Russian ambassador to Turkey, shot live on television; his last moments shared time and again by Twitter and Facebook users, as it is every time a video emerges of the barbaric crimes of ISIS. Anyone connected with someone sharing these videos could have been scrolling through their timelines or news feeds and suddenly been force-fed a snuff video -- hardly fulfilling these companies' promises of a family-friendly, mainstream and safe web experience.  It isn't just snuff or gore, either. Islamist extremists and the far right also operate on major social media platforms. As web users are increasingly concentrated on a small handful of sites, we click shoulder-to-shoulder with the kinds of people sharing the kinds of content we didn't expect nor want in our lives. There's a contradiction here. On the one hand, governments and commentators are calling for social media companies to take greater responsibility for the content on their sites. On the other, these companies are embracing technological change that makes publication quicker, audiences bigger and administration more difficult. If this pattern continues, we can expect further outrages along the lines of the Chicago video, and less patience from governments already keen to pass the buck on Internet governance. Major social media platforms have nothing to gain from hosting this content, of course, but the truth is they are building beasts that they cannot tame. It's clear that 2017 will be a busy year for their policy teams.