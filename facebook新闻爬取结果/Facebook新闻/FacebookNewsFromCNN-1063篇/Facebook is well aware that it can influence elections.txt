During the Republican primaries, Facebook's powerful data told those working to get Ted Cruz elected which ads could win over Donald Trump voters.  One video highlighted Trump's coziness with politicians over the years. The other featured an impassioned Cruz speech about being an outsider who could fix Washington.  The ads were largely informed by and distributed through Facebook. Tommy Swanson, CEO of a digital marketing agency called Stripes, used Facebook's advanced advertising tools to target specific demographics and measure the impact. "Going into Iowa, we already knew which creative was going to turn 40+ year-old female Carson supporters into Cruz supporters," says Swanson, whose agency worked with a super PAC supporting Cruz's candidacy.  Cruz won Iowa, the first state to vote in the primaries, and would go on to win three states on Super Tuesday. One of those was Texas, where Swanson's Facebook campaign led to an "increase in intent to vote for Ted Cruz" among those who had previously  leaned Trump. That point is one of many included among a group of "success stories" for political advertising on Facebook's official marketing page. The stories highlight how political campaigns have used Facebook advertising tools to drive increases in voter registrations, boost support among Hispanics and get voters to pick one candidate over another. Related: Did the internet elect the president? In short, these stories show how Facebook pitches itself as a platform to influence voting decisions just as it does with buying decisions. But you might not know that from listening to its CEO deny that rampant fake news on Facebook could have changed the way people voted in the presidential election. "Personally, I think the idea that fake news on Facebook -- of which it's a small amount of content -- influenced the election in any way is a pretty crazy idea," Mark Zuckerberg said at the Techonomy conference last Thursday. Zuckerberg's point, as he elaborated on later in a Facebook post, was that "only a very small amount" of what shows up in Facebook News Feeds is fake news. "More than 99% of what people see is authentic," he wrote. So how much impact could it really have on the election?  To some who've worked at Facebook, however, Zuckerberg's comments contradict Facebook's pitch to advertisers. Related: Facebook and Google to stop ads from appearing on fake news sites "In 2012, we were pitching political advertisers saying precisely that Facebook could influence voters," says Antonio Garcia-Martinez, who worked as an ads targeting product manager at Facebook until 2013. "Now Zuck is going and saying, 'No that's impossible.'" "Facebook understood that it could throw an election as far back as when I was there," says Garcia-Martinez, author of Chaos Monkeys, about his time working in Silicon Valley. Andy Stone, a spokesman for Facebook, declined to comment beyond Zuckerberg's public statements.  Facebook now finds itself striking a tricky balance. Its core business is built on the premise that advertisers can use Facebook's targeting tools to show the right users the right message at the right time leading to the right outcome. The same dynamic applies to political ads. Citigroup said last month that Facebook and Google would be the "largest recipients of political digital ad spend" from the 2016 election cycle. It even suggested Facebook could top Google for the first time. On the other hand, Facebook doesn't want to be seen as powerful enough to tip elections, deliberately or not.  Related: Facebook shows you what you want to see post-election There is certainly a difference between influencing a few voters through ads or fake news and single-handedly deciding an election. The problem, according to former employees, is that Facebook employees don't always know the full impact that every little tweak to its platform may have on voters.  "This is a very powerful product that can have effects that we didn't imagine it having," says one former Facebook employee, who spoke on condition of anonymity.  Garcia-Martinez recalls one rumor that some Facebook employees were nervous about rolling out a voting prompt to iPhone users first in 2012 because it could have benefited Obama. The reason: iPhone owners might be more likely to live on the coasts and be more liberal.  That might sound ridiculous -- it probably is ridiculous -- but the fear speaks to Facebook's tremendous reach and influence in all things, including voting.  Related: Trump win could be bad news for tech IPOs Judd Antin, a former research manager at Facebook, urged the company to do more surveys and analysis into the fake news problem rather than rely on broad data points like the sweeping 99% figure cited in Zuckerberg's post.  As Antin pointed out in a Medium post this week, that final 1% can still be quite large when you consider more than one billion people check Facebook every day.   "Mark and his leaders seem to have applied their own intuition with a hefty dose of bias and self-interest," Antin wrote. "He jumped to conclusions about what it means and why, likely in the absence of good information about how fake news can matter."  "When data-driven becomes data-myopic, we all suffer," Antin added. "I worry that Facebook's decision-making has lost its humanity. And that's frightening given the central role it plays in our world."