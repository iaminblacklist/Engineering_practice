During the U.S. election, hackers used Facebook to spread bad information. These weren't the stereotypical hackers after your passwords or credit cards -- these hackers wanted to control your opinion. In a new paper released Thursday, Facebook uses these efforts as a case study to outline how it combats what it calls "Information Operations." These are the ways governments or non-state actors use Facebook to manipulate political opinions and change the outcome of current events.  Information operations include strategies like using fake accounts to spread false information, hijacking popular topics or manipulating likes on Facebook posts. Bad actors can turn the platform we use to connect with friends and read news into a tool to manipulate our opinions. "Information operators may attempt to distort public discourse, recruit supporters and financiers, or affect political or military outcomes," the authors wrote. "These activities can sometimes be accomplished without significant cost or risk to their organizers." The paper was published by Alex Stamos, Facebook's chief security officer, and security engineers Jen Weedon and William Nuland. It explains the nefarious strategies in detail, alongside what the company is doing to fix it.  Facebook's work to combat this behavior isn't new, but the report sheds more light on its process. The authors said Facebook has an "increasing role" in "civic discourse," so it wants to be more transparent about how the platform can be used to shift perspectives.  Related: How Russia hacks you There are three main pieces to an information operations campaign, according to the paper: data collection, content creation and false amplification. That means stealing and publishing information that's not public, creating fake accounts, and people working collectively to spread bad information. Facebook does not name any countries or people behind information operations campaigns. But Facebook said its data "does not contradict" what the federal government said in January -- that Russia interfered with the U.S. election.  The company is working to prevent these kinds of organized campaigns by automatically identifying strange behavior through machine learning. Facebook's algorithms can block bots from making fake accounts and recognize when an account posts the same stuff multiple times or if they send a lot of messages. Facebook detected and took action against 30,000 fake accounts in France, the company said earlier this month. Facebook owning its role in shaping current events is a big change from what CEO Mark Zuckerberg initially said after the U.S. election.  "I think the idea that fake news on Facebook ... influenced the election in any way is a pretty crazy idea," Zuckerberg said at a conference in November. He later walked back those comments, and said in February that it was Facebook's responsibility "to amplify the good effects and mitigate the bad."