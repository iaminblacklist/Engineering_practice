Facebook defended and clarified a new initiative Thursday that combats revenge pornography on the platform by essentially having people send nude photos or videos to the social media company.
In order to utilize the program, which is organized through a partnership with the Australian government, certain users send themselves the content believed to be widely circulated against their consent via Messenger. Facebook will then use technology to create a digital fingerprint or link, according to the Australian Broadcasting Corporation (ABC), which would subsequently be employed as way to match it with preexisting content on the main platform, as well as Instagram (which Facebook owns) and Messenger.
But many people are somewhat skeptical about the prospect of sending a massive tech conglomerate their explicit, personal photos — even though the content is likely already out there and available for Facebook employees to view and do with it as they please.
“We don’t want Facebook to be a place where people fear their intimate images will be shared without their consent. We’re constantly working to prevent this kind of abuse and keep this content out of our community,” Antigone Davis, global head of safety at Facebook, wrote on a company blog post. “We recently announced a test that’s a little different from things we’ve tried in the past. Even though this is a small pilot, we want to be clear about how it works.”
Davis says Facebook already has a feature by which users can report an image shared on the platform without the subject’s consent. But the new test will provide “an emergency option for people to provide a photo proactively to Facebook, so it never gets shared in the first place.”
So essentially, if a person has an intimate photo that they want no one else to see except for perhaps very particular recipients, Facebook says they should consider also voluntarily sending that photo to operators of the world’s largest social network to ostensibly ensure that it stays limited to only those intended.
People, including public officials , are already worried about tech companies’ utilization of user data. Willingly giving explicit images, like nude photos, to yet another entity, may not be easy for some of the more distrustful users. Nevertheless, the test still could prove to be one of the most viable options as the issue of revenge porn and appropriately and effectively combatting is certainly complex. (RELATED: Social Media Site Reveals 300 Anonymous Users’ Personal Info To Revenge Porn Victim)
“Facebook has been at the forefront of the tech industry’s efforts to develop innovative and efficient responses to the problem of nonconsensual pornography,” Mary Anne Franks, a professor at the University of Miami School of Law, wrote in Facebook’s blog post. “Many victims live in fear of having their intimate images exposed, and this pilot program allows those victims to act preemptively against this threat.”
Facebook announced in April that it was introducing a number of new preventative tools to help purge “revenge porn” from its platform. One of the measures is identifying and cataloging specific images already reported through “ photo-matching technologies ,” which appears to be a critical component of the latest initiative with Australia.
Facebook declined to elaborate on the details beyond the post by Davis after The Daily Caller News Foundation reached out.
 [email protected] .