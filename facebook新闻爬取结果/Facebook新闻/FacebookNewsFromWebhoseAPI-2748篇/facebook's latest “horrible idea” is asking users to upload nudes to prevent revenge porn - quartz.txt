Machines with Brains November 09, 2017 
Out of all the major tech companies, surveys show that users trust Facebook the least, so it should come as no surprise that its newest controversial idea was met with the simple reaction : “nope.” In a test, the company is asking users to upload their nude photos, in order to prevent future “revenge porn” against them. 
“Revenge porn” is otherwise known as non-consensual pornography, since it involves someone sharing nude or NSFW images online without the subject’s consent. It’s often perpetuated by ex-partners. Although some cyber civil rights activists have lauded Facebook’s idea, a cybersecurity expert told Quartz that it was “horrible.” 
Chris Hadnagy, a US security consultant and ethical hacker who founded a nonprofit that helps track child pornography online , said, among other things, uploading your nude photos to Facebook means that you’re giving your most intimate information to a third party in a transaction that “seems insecure.” Moreover, he said, the process created a false sense of security: “What if it was not “THAT” image that your ex uploaded? What if it was an image you didn’t give to Facebook to hash and store?” 
A Facebook spokesperson told Quartz that its process is akin to fingerprinting. A concerned user uploads the photo to a message to themselves in Messenger, Facebook’s chat app. If a photo is determined to violate Facebook’s policies (presumably nudity in this case), it is “hashed,” so assigned a “fingerprint,” which Facebook stores. 
A Facebook analyst then reviews the image. The user is then asked to delete the photo from the Messenger thread. If someone uploads the same image to Facebook in the future, it will be run through a database of these fingerprints. If there’s a match, the photo is blocked from being shared on the platform. Facebook is running its tests in Australia in partnership with local authorities, and were first reported by the country’s ABC News. 
Facebook didn’t reveal many details about the tests. We asked whether the images would be used as training data for Facebook’s artificial intelligence, which would add the nudes into a massive pool of data that Facebook users share publicly, which the company can scrape and analyze for its own uses. 
Facebook said this was not the case. 
Dave Gershgorn contributed reporting.