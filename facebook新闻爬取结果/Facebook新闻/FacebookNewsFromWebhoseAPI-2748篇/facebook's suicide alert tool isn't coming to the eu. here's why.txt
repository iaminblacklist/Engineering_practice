Ocado's unexciting vision for the future of robots sucks... literally 10:00 AM Stephen Hawking: 'I fear AI may replace humans altogether' 8:00 AM This is how Transport for London will bring mobile signal to the Tube 1 day ago How do you detect the distant sound of an exploding submarine? 1 day ago How Eivør is making the sound of Faroese folk music a global hit 8:00 AM Line of Duty and 26 of the best TV series on Netflix UK 4 days ago How Duolingo uses dirty gaming tricks to get you addicted to French 3 days ago Crowdfunded furniture is helping designers develop new ideas 1 day ago Reddit can't work out whether to save or destroy net neutrality 3 days ago This London restaurant is using 3D projection to bring food to life 3 days ago The ingenious technology behind Blue Planet II 1 day ago Beijing's Leeza Soho is more sci-fi spectacular than skyscraper 2 days ago The best wireless multi-room speakers 3 days ago If you can't build it, buy it: Google's biggest acquisitions mapped 3 days ago YouTube, kids and Silicon Valley's recurring algorithmic blind spot 4 days ago Facebook Facebook's suicide alert tool isn't coming to the EU. Here's why 
Europe is too sensitive to privacy for a pattern-recognition tool that aims to prevent self harm, Facebook argues, but such a system fits our data laws Tuesday 28 November 2017 Facebook 
Facebook is scanning posts for suicidal ideation everywhere in the world — except Europe. But despite Facebook's claims we're too sensitive about privacy issues to accept site-wide scanning, there's plenty in our data laws that would allow automated alerts to protect social media users here, too. Advertisement 
Everywhere else but here, Facebook will use a pattern-recognition system to watch for troubling comments in users posts and videos, such as "are you ok?", as indications someone may need mental-health help, passing their details onto emergency responders to intervene. "We are starting to roll out artificial intelligence outside the US to help identify when someone might be expressing thoughts of suicide, including on Facebook Live," said Guy Rosen, VP of Product Management, in a blogpost . "This will eventually be available worldwide, except the EU." 
Amid suggestions Europe was excluded because of our tighter data laws, WIRED asked Facebook why Europe was being left out. A spokesperson didn't specifically mention the incoming General Data Protection Regulation (GDPR) or existing data laws, but said it was down to local sensitivity around such issues. 
Tim Turner, a data protection consultant at 2040 Training, said GDPR need not scupper the pattern-recognition system here in the UK or in Europe — our laws aren't that onerous that a wealthy company can't make it work. Read next Uploading all your nudes to Facebook isn't such a bad idea By James Temperton 
But if complying is possible, why isn't Facebook making the effort to do so here in the EU? "I have to wonder if this is a shot across the EU’s bows," said Turner. "Facebook perhaps wants to undermine the GDPR — which doesn’t change many of the legal challenges significantly for this — and they’re using this as a method to do so." 
Turner added: "Nobody could argue with wanting to save lives, and it could be a way of watering down [data protection] legislation that is a challenge to Facebook’s data hungry business model. Without details of what they think the legal problems are with this, I’m not sure they deserve the benefit of the doubt." Advertisement 
If Facebook did decide to roll out the system here, there's two main ways it could work within our data protection regulations: under legitimate interests justifications, or with consent. 
First, Facebook could argue that ignoring privacy is valid here because the system will potentially save lives, a "legitimate interest" test that balances preventing suicides with the analysis of everyone on Facebook. "They can make a robust public justification based on… legitimate interests and then allow people to test their reasoning," Turner told WIRED. 
The second way Facebook could avoid data law concerns is by asking for consent, perhaps by making the system opt-in. However, in the US and elsewhere, users won't even be able to opt-out. Read next You can now transfer money on Facebook Messenger in the UK By Matt Burgess Advertisement 
As this is health information, there are extra concerns in existing data laws and GDPR, noted Paul Bernal, lecturer in IT at the University of East Anglia's school of law . "Facebook will be creating brand new ‘sensitive personal data’ by flagging someone up as a suicide risk — that’s already a problem under existing rules, but much more of a problem under the GDPR," he told WIRED. "Facebook users would have to consent to be scanned — not just consent to receive help, as seems to be the plan. Explicit, informed consent is required. Is that here? No." 
In other words, if Facebook wanted to roll the automated alert system out in the EU without tripping over data laws, it need only be made opt-in. And if that were the case, plenty may well let Facebook scan their posts and messages, Turner argues. "I expect that there would be people who know their vulnerabilities and might be willing to allow this for moments when they’re suffering." 
Facebook isn't the first to try to leverage what we say on social media into an early-warning alert for suicide and self harm. Back in 2014, Samaritans unveiled its Radar app, which scanned tweets looking for key words and phrases that could signal intent to self harm, such as "tired of being alone" or "need someone to talk to". It was pulled within days after a public backlash, but the Information Commissioner's Office — the UK's data watchdog — also looked into whether it complied with the Data Protection Act. In a letter revealed via a Freedom of Information Act request , the ICO said Radar was "unlikely to be compliant". 
The Samaritans system had a few key differences, notably that it alerted a person's Twitter followers of their mental state rather than just authorities — opening up a clear possibility of bullying of already vulnerable people. "Facebook don’t need to make the same mistakes," Turner said. 
If the system actually works to prevent suicide, does that mean Europeans are being left at risk? Experts at mental health charities Mind and Sane have previously welcomed automated tools . French researchers suggested machine learning can "identify suicidal ideation with high precision", while academics at the Chinese Academy of Sciences found evidence that social media could be used for suicide prevention. Microsoft researchers suggest social media can be used to detect and diagnose depressive disorders. 
But if Facebook's pattern-recognition system does save lives, it's all the more reason to do it right from the start. Doing otherwise may scare the most vulnerable people off the platform, Bernal said. "Samaritans Radar was seen by many in the mental health community as dangerous — they don’t like being monitored and fear being ‘sold out’ to mental health services," Bernal said. "Many have had bad experiences with those services and if they thought those services would be able to monitor their mental state without their consent they would be ‘chilled’. Some said they would abandon Twitter if this happened." Advertisement 
Regardless of the success of the automated alerts — and regardless if it ever comes to these more sensitive shores — we need human help online, too. Indeed, Facebook's system isn't wholly automated. Alongside the pattern-recognition system, Facebook's Rosen also said the company was making non-tech efforts, including "improving how we identify appropriate first responders" and "dedicating more reviewers from our community operations team to review reports of suicide or self harm." WIRED asked if those improvements would be extended to Europe, but hasn't yet had a response on that particular query. If we are left without such supports, at least Facebook last year improved its user-driven reporting tools , making it easier to tell the site if someone — yourself, or someone you follow — was clearly in distress. Use them if you need them. 
Need help? Contact Samaritans anytime on 116 123 in the UK and Ireland.