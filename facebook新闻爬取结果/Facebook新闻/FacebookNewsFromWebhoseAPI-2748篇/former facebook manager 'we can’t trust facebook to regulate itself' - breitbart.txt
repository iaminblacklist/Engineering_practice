Former Facebook Manager: ‘We Can’t Trust Facebook to Regulate Itself’ The Associated Press by Lucas Nolan 20 Nov 2017 0 20 Nov, 2017 20 Nov, 2017 A former manager at Facebook recently published an op-ed in the New York Times describing the company’s attitude towards user privacy and warning that Facebook is not capable of regulating itself. 
In a recent New York Times op-ed , former Facebook Platform Operations Manager Sandy Parakilas discussed his time at Facebook from 2011 until 2012. During this time, Parakilas came to the conclusion that Facebook cared more about collecting data from Facebook users than protecting them from online harassment and abuse. Parakilas states that as Facebook comes under increased scrutiny from the government, Facebook cannot be trusted to regulate itself. advertisement 
Parakila explains why user data is so valuable to Facebook in his NYT op-ed saying: Facebook knows what you look like, your location, who your friends are, your interests, if you’re in a relationship or not, and what other pages you look at on the web. This data allows advertisers to target the more than one billion Facebook visitors a day. It’s no wonder the company has ballooned in size to a $500 billion behemoth in the five years since its I.P.O. The more data it has on offer, the more value it creates for advertisers. That means it has no incentive to police the collection or use of that data — except when negative press or regulators are involved. Facebook is free to do almost whatever it wants with your personal information, and has no reason to put safeguards in place. For a few years, Facebook’s developer platform hosted a thriving ecosystem of popular social games. Remember the age of Farmville and Candy Crush? The premise was simple: Users agreed to give game developers access to their data in exchange for free use of addictive games. Parakila explained that this meant Facebook had little control over how their user’s data was used once it was passed onto the game developers, if a developer decided to misuse that user information the most Facebook could do was threaten to cut off their developer access. This was an issue that Parakila was tasked with fixing, as Facebook’s I.P.O date approached, Parakila had to figure out how to protect Facebook user’s data from being abused by developers. Parakila then lists some of the odd actions taken by developers with access to Facebook user data: In one instance, a developer appeared to be using Facebook data to automatically generate profiles of children, without their consent. When I called the company responsible for the app, it claimed that Facebook’s policies on data use were not being violated, but we had no way to confirm whether that was true. Once data passed from the platform to a developer, Facebook had no view of the data or control over it. In other cases, developers asked for permission to get user data that their apps obviously didn’t need — such as a social game asking for all of your photos and messages. People rarely read permissions request forms carefully, so they often authorize access to sensitive information without realizing it. Parakila discussed Facebook’s obsession with negative press and their willingness to allow developers misusing user data to continue operating once Facebook doesn’t suffer any negative fallout: At a company that was deeply concerned about protecting its users, this situation would have been met with a robust effort to cut off developers who were making questionable use of data. But when I was at Facebook, the typical reaction I recall looked like this: try to put any negative press coverage to bed as quickly as possible, with no sincere efforts to put safeguards in place or to identify and stop abusive developers. When I proposed a deeper audit of developers’ use of Facebook’s data, one executive asked me, “Do you really want to see what you’ll find?” The message was clear: The company just wanted negative stories to stop. It didn’t really care how the data was used. Parakila has a solution for Facebook that echoes Breitbart News Executive Chairman Steve Bannon’s previous proposal , a breakup of the large tech companies and further regulation and safeguards ensuring that the company is forced to secure their user’s data. This makes for a dangerous mix: a company that reaches most of the country every day and has the most detailed set of personal data ever assembled, but has no incentive to prevent abuse. Facebook needs to be regulated more tightly, or broken up so that no single entity controls all of its data. The company won’t protect us by itself, and nothing less than our democracy is at stake. 
Read the full op-ed in the New York Times here. 
Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan_ or email him at lnolan@breitbart.com . Read More Stories About: 
Comment count on this article reflects comments made on Breitbart.com and Facebook. Visit Breitbart's Facebook Page . BREITBART CONNECT