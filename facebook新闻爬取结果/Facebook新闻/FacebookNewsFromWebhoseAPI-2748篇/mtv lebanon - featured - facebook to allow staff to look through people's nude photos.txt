SIGN UP TO OUR NEWSLETTER GET MTV NEWS STRAIGHT TO YOUR INBOX Thank you You are now subscribed to MTV newsletter Facebook to Allow Staff to Look Through People's Nude Photos By (The Independent - Andrew Griffin) /November 11, 2017 0 ADVERTISE ON MTV The Independent - Andrew Griffin Facebook is allowing its staff to look at nude photos of its users in an attempt to combat revenge porn. The site has told its users to send in any photos that they are afraid might be circulated on the site. Those images will then be viewed by Facebook's own staff to verify them, and if they are decided to be legitimate they will be banned from being shared on the site. In a post aimed at clarifying the facts around the new initiative, Facebook makes clear that those images will only be seen by "a specially trained representative from our Community Operations team". But it does confirm that all of the images will be looked at by its own staff. "We don’t want Facebook to be a place where people fear their intimate images will be shared without their consent," the post, written by Facebook's global head of safety Antigone Davis, reads. "We’re constantly working to prevent this kind of abuse and keep this content out of our community." It then goes on to lay out the details of the plan to stop the sharing of non-consensual intimate images, many of which were reported in the press. The article, titled 'The Facts', appears to be an attempt to address some of the misconceptions around the story - but does in fact confirm many of its most controversial details. Most of the process is automated. Once a photo is verified, it will be converted into a numerical representation called a hash that can only be read by computers, not humans - and any picture that is uploaded will be checked against these hashes to ensure that it isn't on the list of Facebook's banned pictures. But the site will only allow that to happen if someone sends a photo to Facebook first, at which point it will be checked over by one of the site's own staff. The feature is currently being rolled out in Australia, in partnership with the country's eSafety Commissioner’s Office and a number of experts and surivors. Those experts have praised the work to identify and ban non-consensual naked images - but the decision to only do so after a person has looked at the photos has drawn intense criticism. يمكنكم نشر مقتطفات من المقال الحاضر، ما حده الاقصى 25% من مجموع المقال، شرط: ذكر اسم المؤلف والناشر ووضع رابط الـ MTV الإلكتروني (URL) الذي يحيل الى مكان مصدر المقال، تحت طائلة تطبيق احكام قانون حماية الملكية الفكرية.